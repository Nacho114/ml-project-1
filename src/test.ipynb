{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import loader\n",
    "import implementations as impl\n",
    "\n",
    "\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = loader.load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute new_tX : column of ones followed by tX\n",
    "first_col = np.ones((tX.shape[0],1))\n",
    "new_tX = np.concatenate((first_col, tX), axis=1)\n",
    "new_tX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_fun(n_iter, max_iters, loss, w):\n",
    "#     print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(\n",
    "#                     bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import debugger \n",
    "\n",
    "\n",
    "debugger = debugger.Debugger(['loss', 'w'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_batch set to 1 as batch_size is None\n"
     ]
    }
   ],
   "source": [
    "from utils import debugger \n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.0000001 \n",
    "# 0.00000001 : after 50 iterations : 556513.5 loss\n",
    "# 0.0000001 : after 50 iterations : 97535 loss\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.ones((31,))\n",
    "\n",
    "debugger = debugger.Debugger(['loss', 'w'])\n",
    "# Start gradient descent.\n",
    "gradient_losses, gradient_ws = impl.least_squares_GD(y, new_tX, w_initial, max_iters, gamma, debugger=debugger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEDCAYAAADOc0QpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nW4StK8T5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "debugger.plot('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.0000001 # loss = 90047\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.ones((31,))\n",
    "\n",
    "# Start gradient descent.\n",
    "stoch_gradient_losses, stoch_gradient_ws = impl.least_squares_SGD(y, new_tX, w_initial, max_iters, gamma, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least squares regression using normal equations\n",
    "def least_squares(y, tx):\n",
    "    # TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression using normal equations\n",
    "def ridge_regression(y, tx, lambda_):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression using gradient descent or SGD\n",
    "def logistic_regression(y, tx, initial_w, max_iters, gamma):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularized logistic regression using gradient descent or SGD\n",
    "def reg_logistic_regression(y, tx, lambda_, initial_w, max_iters, gamma):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
